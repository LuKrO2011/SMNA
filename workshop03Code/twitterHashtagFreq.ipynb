{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "COSC2671 Social Media and Network Analytics \n",
    "\n",
    "Workshop 3\n",
    "\n",
    "Jeffrey Chan, RMIT University, 2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getHashtags(tweet):\n",
    "    \"\"\"\n",
    "    Extracts the associated hashtags of tweet.\n",
    "\n",
    "    @param tweet: The tweet, which is in the tweepy json format, and which we wish to extract its associated hashtags.\n",
    "\n",
    "    @returns: list of hashtags (in lower case)\n",
    "    \"\"\"\n",
    "    entities = tweet.get('entities', {})\n",
    "    hashtags = entities.get('hashtags', [])\n",
    "\n",
    "    return [tag['tag'].lower() for tag in hashtags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following does bulk of the work.  It calls getHasTags to extract out the appropriate hastags.  Study this carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigir2022: 9\n",
      "waiawards2022anz: 3\n",
      "nlproc: 2\n",
      "interdisciplinary: 1\n",
      "research: 1\n",
      "impact: 1\n",
      "clinicalnlp: 1\n",
      "tb: 1\n",
      "misinformation: 1\n",
      "alta: 1\n",
      "adelaide: 1\n",
      "adms2022: 1\n",
      "pandemic: 1\n",
      "bioinformatics: 1\n",
      "phd: 1\n",
      "digihealthfest2022: 1\n",
      "digitalhealth: 1\n",
      "digihealthfest22: 1\n",
      "hci: 1\n",
      "userexperience: 1\n",
      "vr: 1\n",
      "datascience: 1\n",
      "searchengines: 1\n",
      "phdlife: 1\n",
      "waiawarda2022anz: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# load json file\n",
    "# note usually we would do some checks, but for clarify's sake we haven't implement that code here\n",
    "fJsonName = 'rmitCsTwitterTimeline.json'\n",
    "\n",
    "# number of tweets to display\n",
    "tweetThres = 50\n",
    "\n",
    "# open file and use Counter to count the number of times the hash tags appears\n",
    "with open(fJsonName, 'r') as f:\n",
    "    hashtagsCounter = Counter()\n",
    "    \n",
    "    dTweets = json.load(f)\n",
    "    # for each line in file (which corresponds to a tweet), load it, get the hashtags and insert them into the\n",
    "    # Counter\n",
    "    for tweet in dTweets['data']:\n",
    "        hashtagsInTweet = getHashtags(tweet)\n",
    "        hashtagsCounter.update(hashtagsInTweet)\n",
    "\n",
    "    for tag, count in hashtagsCounter.most_common(tweetThres):\n",
    "        print(tag + \": \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}