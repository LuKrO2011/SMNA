{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSC2671 Social Media and Network Analytics\n",
    "\n",
    "# Assignment 2 - Twitter posts downloader\n",
    "\n",
    "@author Lukas Krodinger, s3961415\n",
    "\n",
    "Note that this notebook requires the file twitterClient.py written by Jeffrey Chan with a valid twitter bearerToken, where the limit is not exceeded in order to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import twitterClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_tweets(filename):\n",
    "    \"\"\"\n",
    "    Loads the tweets from the file with the given name into an array of tweets.\n",
    "\n",
    "    @param filename: The filename of the file to load the tweets from.\n",
    "\n",
    "    @returns: An array of tweets.\n",
    "    \"\"\"\n",
    "    tweets = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for sLine in f:\n",
    "            tweet = json.loads(sLine)\n",
    "            tweets.append(tweet)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = twitterClient.twitterClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here, I define the search query, what fields of each tweet to download, the maximum amount of downloaded tweets as well as the name of the output json file.\n",
    "\n",
    "My search focuses on ...\n",
    "I want to download all tweet fields supported by tweepy and requiring no authentication, as one can still filter out the required fields for analysis later on.\n",
    "Note that the max_tweets might not be reached, because I only download tweets which are at most one-week-old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define what tweets do download\n",
    "search_query = 'tennis -table'\n",
    "\n",
    "# All non-authenticated tweet fields\n",
    "all_tweet_fields = ['id', 'text', 'attachments', 'author_id', 'context_annotations', 'conversation_id', 'created_at', 'entities', 'geo', 'in_reply_to_user_id', 'lang', 'possibly_sensitive', 'public_metrics', 'referenced_tweets', 'reply_settings', 'source', 'withheld']\n",
    "\n",
    "# The maximum amount of tweets to download\n",
    "max_tweets = 100  # 50000 was used here\n",
    "\n",
    "# The filename of the file to store the tweets into\n",
    "all_twitter_fields_filename = \"../data/tennis_2023_05_05.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I download the tweets via the tweepy client in a paginated manner (100 at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "99\n",
      "Number of tweets downloaded:  198\n",
      "b26v89c19zqg8o3fqkg04s2kz1yxu8yht93hqz6g2anb1\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "# try:\n",
    "#     # Download the tweets paginated, 100 at once\n",
    "#     for tweet in tweepy.Paginator(client.search_recent_tweets, search_query, max_results=100, tweet_fields=all_tweet_fields).flatten(limit=max_tweets):\n",
    "#         tweets.append(tweet)\n",
    "# finally:\n",
    "#     print(len(tweets))\n",
    "\n",
    "\n",
    "twitterResponse = client.search_recent_tweets(search_query, max_results=100, tweet_fields=all_tweet_fields) #until=date_until\n",
    "while len(tweets) < max_tweets:\n",
    "    try:\n",
    "        twitterResponse = client.search_recent_tweets(search_query, max_results=100, tweet_fields=all_tweet_fields, next_token =twitterResponse.meta.get(\"next_token\"))\n",
    "    except:\n",
    "        break\n",
    "    finally:\n",
    "        print(len(tweets))\n",
    "\n",
    "    if twitterResponse.data is not None:\n",
    "        for tweet in twitterResponse.data:\n",
    "            tweets.append(tweet)\n",
    "\n",
    "print(\"Number of tweets downloaded: \", len(tweets))\n",
    "print(twitterResponse.meta.get(\"next_token\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b26v89c19zqg8o3fpzbngfdivtupw624idr1ro4wl0dbx\n",
    "b26v89c19zqg8o3fpzbngdaan5f7ocvpscb5vemqqlif1\n",
    "b26v89c19zqg8o3fpzbngdaafj8qv80nifj3dw5sl59j1\n",
    "\n",
    "b26v89c19zqg8o3fpzbn1e117y06l7zcelrqn0zafzcl9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now I store the downloaded tweets to the specified output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets successfully stored to:  ../data/tennis_2023_05_05.json\n"
     ]
    }
   ],
   "source": [
    "with open(all_twitter_fields_filename, 'w') as json_file:\n",
    "    for tweet in tweets:\n",
    "        json.dump(tweet.data, json_file)\n",
    "        json_file.write('\\n')\n",
    "\n",
    "print(\"Tweets successfully stored to: \", all_twitter_fields_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (v3.10.1:2cd268a3a9, Dec  6 2021, 14:28:59) [Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
